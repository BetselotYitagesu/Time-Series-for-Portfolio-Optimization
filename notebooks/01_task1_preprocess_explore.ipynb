{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836952af",
   "metadata": {},
   "source": [
    "# 01_task1_preprocess_explore.ipynb\n",
    "\n",
    "# Task 1: Preprocess and Explore Financial Data for Portfolio Optimization\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we perform Task 1 of the portfolio optimization project for GMF Investments.\n",
    "\n",
    "The objectives are:\n",
    "- Download historical adjusted closing price data for TSLA, BND, and SPY from 2015 to 2025.\n",
    "- Clean and preprocess the data.\n",
    "- Conduct exploratory data analysis (EDA) to understand trends, volatility, and anomalies.\n",
    "- Test stationarity using Augmented Dickey-Fuller tests.\n",
    "- Calculate foundational risk metrics like Value at Risk (VaR) and Sharpe Ratio.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db0a6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def load_stock_data(tickers: List[str], start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads adjusted close price data for given tickers.\n",
    "\n",
    "    Args:\n",
    "        tickers (List[str]): List of stock/ETF symbols.\n",
    "        start (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end (str): End date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Adjusted close prices with tickers as columns.\n",
    "    \"\"\"\n",
    "    # Download historical data\n",
    "    data = yf.download(tickers, start=start, end=end)\n",
    "\n",
    "    # Safety check for no data\n",
    "    if data is None or data.empty:\n",
    "        raise ValueError(f\"No data returned from Yahoo Finance for tickers: {tickers}\")\n",
    "\n",
    "    # Check if data columns are MultiIndex (for multiple tickers)\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        # Select the 'Adj Close' level data\n",
    "        if \"Adj Close\" in data.columns.levels[0]:\n",
    "            adj_close = data.loc[:, \"Adj Close\"]\n",
    "        else:\n",
    "            raise ValueError(\"'Adj Close' not found in downloaded data columns.\")\n",
    "    else:\n",
    "        # Single ticker case, just take 'Adj Close' column\n",
    "        if \"Adj Close\" in data.columns:\n",
    "            adj_close = data[\"Adj Close\"]\n",
    "        else:\n",
    "            raise ValueError(\"'Adj Close' not found in downloaded data columns.\")\n",
    "\n",
    "    # Ensure output is always a DataFrame (for single ticker)\n",
    "    if isinstance(adj_close, pd.Series):\n",
    "        adj_close = adj_close.to_frame()\n",
    "\n",
    "    return adj_close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26b0b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "from src.data_loader import load_stock_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754ab93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load and Inspect Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "215d87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List\n",
    "\n",
    "def load_stock_data(tickers: List[str], start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download adjusted close prices for given tickers using auto_adjust.\n",
    "\n",
    "    Returns a DataFrame with tickers as columns and dates as index.\n",
    "    \"\"\"\n",
    "    data = yf.download(\n",
    "        tickers,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        progress=False,\n",
    "        auto_adjust=True,  # <- Adjust prices, so Close = Adj Close\n",
    "        group_by='ticker',\n",
    "    )\n",
    "    \n",
    "    # When multiple tickers and group_by='ticker', columns are multi-indexed:\n",
    "    # each ticker is a top-level column, with sub-columns Open, High, Low, Close, Volume.\n",
    "    # So we extract Close price per ticker.\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        close_df = pd.DataFrame()\n",
    "        for ticker in tickers:\n",
    "            close_df[ticker] = data[ticker]['Close']\n",
    "    else:\n",
    "        # Single ticker case\n",
    "        close_df = data['Close'].to_frame()\n",
    "\n",
    "    close_df.index.name = 'Date'\n",
    "    return close_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6183924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tickers and date range\n",
    "tickers = [\"TSLA\", \"BND\", \"SPY\"]\n",
    "start_date = \"2015-07-01\"\n",
    "end_date = \"2025-07-31\"\n",
    "\n",
    "# Load data\n",
    "adj_close_df = load_stock_data(tickers, start_date, end_date)\n",
    "adj_close_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2a355",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "- Check for missing values.\n",
    "- Forward-fill or back-fill missing data if any.\n",
    "- Calculate daily returns and log returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc9d30",
   "metadata": {},
   "source": [
    "## Install note (if needed)\n",
    "\n",
    "Run this in your activated `.venv` (Windows PowerShell):\n",
    "\n",
    "```powershell\n",
    "pip install yfinance pandas numpy matplotlib seaborn statsmodels jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f044dc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'prepare_and_save_all' from 'src.data_loader' (e:\\Tenx\\Week11\\Time Series for Portfolio Optimization\\notebooks\\..\\src\\data_loader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      8\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# allow importing src package from notebook\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_and_save_all, PROCESSED_DIR  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[32m     13\u001b[39m START = \u001b[33m\"\u001b[39m\u001b[33m2015-07-01\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'prepare_and_save_all' from 'src.data_loader' (e:\\Tenx\\Week11\\Time Series for Portfolio Optimization\\notebooks\\..\\src\\data_loader.py)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "### Cell 4 (Code)\n",
    "```python\n",
    "\"\"\"\n",
    "# Import helper and load data\n",
    "import sys\n",
    "sys.path.append(\"..\")  # allow importing src package from notebook\n",
    "\n",
    "from src.data_loader import prepare_and_save_all, PROCESSED_DIR  # noqa: E402\n",
    "\n",
    "# parameters\n",
    "START = \"2015-07-01\"\n",
    "END = \"2025-07-31\"\n",
    "TICKERS = [\"TSLA\", \"BND\", \"SPY\"]\n",
    "\n",
    "# download and prepare (will skip if files already exist)\n",
    "prepare_and_save_all(TICKERS, START, END)\n",
    "\n",
    "# load processed files into dict\n",
    "dfs = {}\n",
    "for t in TICKERS:\n",
    "    path = PROCESSED_DIR / f\"{t}_processed.csv\"\n",
    "    dfs[t] = pd.read_csv(path, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "    print(t, dfs[t].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ab767",
   "metadata": {},
   "source": [
    "## Quick data checks\n",
    "\n",
    "- Show head/tail\n",
    "- Data types\n",
    "- Missing value counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613058fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, df in dfs.items():\n",
    "    print(f\"--- {t} ---\")\n",
    "    display(df.head())\n",
    "    print(\"dtypes:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"missing values:\")\n",
    "    print(df.isna().sum())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9f5c3",
   "metadata": {},
   "source": [
    "## Price series — Adj Close / Price\n",
    "\n",
    "Plot each asset's price over time. Visualize on the same chart\n",
    "and with log scale for TSLA to show long-term trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "for t in TICKERS:\n",
    "    plt.plot(dfs[t][\"price\"], label=t)\n",
    "plt.title(\"Adjusted Close / Price (2015-07-01 → 2025-07-31)\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# TSLA log scale\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(dfs[\"TSLA\"][\"price\"].dropna(), label=\"TSLA\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"TSLA Price (log scale)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827355e",
   "metadata": {},
   "source": [
    "## Daily returns & distributions\n",
    "\n",
    "Plot daily returns time series and distribution (histogram + KDE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d754de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "for i, t in enumerate(TICKERS):\n",
    "    ax_ts = axes[i, 0]\n",
    "    ax_dist = axes[i, 1]\n",
    "    dfs[t][\"return\"].plot(ax=ax_ts, title=f\"{t} daily returns\")\n",
    "    sns.histplot(dfs[t][\"return\"].dropna(), kde=True, ax=ax_dist)\n",
    "    ax_dist.set_title(f\"{t} return distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f4b29",
   "metadata": {},
   "source": [
    "## Rolling statistics — mean & volatility\n",
    "\n",
    "Compute 21-day rolling mean and annualized rolling volatility\n",
    "(21-day window ~ 1 month).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "for t in TICKERS:\n",
    "    plt.plot(\n",
    "        dfs[t][\"rolling_mean\"].rolling(window=5).mean(),\n",
    "        label=f\"{t} rolling mean (smoothed)\",\n",
    "    )\n",
    "plt.title(\"Rolling mean (log returns, smoothed)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for t in TICKERS:\n",
    "    plt.plot(dfs[t][\"rolling_vol\"], label=f\"{t} rolling vol (21d, ann)\")\n",
    "plt.title(\"Rolling annualized volatility (21d)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9490346",
   "metadata": {},
   "source": [
    "## Outlier detection — extreme return days\n",
    "\n",
    "List top 5 gains and top 5 losses per ticker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8aa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TICKERS:\n",
    "    print(f\"--- {t} top 5 gains ---\")\n",
    "    display(dfs[t][\"return\"].nlargest(5))\n",
    "    print(f\"--- {t} top 5 losses ---\")\n",
    "    display(dfs[t][\"return\"].nsmallest(5))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902da536",
   "metadata": {},
   "source": [
    "## Stationarity tests (ADF)\n",
    "\n",
    "We run Augmented Dickey-Fuller on price and log returns.\n",
    "Interpretation:\n",
    "- p-value < 0.05 => reject unit root => stationary.\n",
    "- Price series are typically non-stationary.\n",
    "- Log returns are often stationary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48619eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_report(series, name):\n",
    "    s = series.dropna()\n",
    "    res = adfuller(s, autolag=\"AIC\")\n",
    "    stat, pval, usedlag = res[0], res[1], res[2]\n",
    "    print(f\"{name}: ADF stat={stat:.4f}, p-value={pval:.4f}, lag={usedlag}\")\n",
    "\n",
    "for t in TICKERS:\n",
    "    print(f\"=== {t} ===\")\n",
    "    adf_report(dfs[t][\"price\"], f\"{t} price\")\n",
    "    adf_report(dfs[t][\"log_return\"], f\"{t} log return\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2222e39",
   "metadata": {},
   "source": [
    "## Risk metrics: VaR (95%) and Annualized Sharpe\n",
    "\n",
    "- VaR (95%) computed from daily returns historical distribution.\n",
    "- Sharpe uses mean/std of daily returns annualized by sqrt(252).\n",
    "  We assume risk-free rate ~ 0 for this task; you can adjust later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb85f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_sharpe(df, p=0.95):\n",
    "    r = df[\"return\"].dropna()\n",
    "    var95 = -np.percentile(r, (1 - p) * 100)\n",
    "    mean = r.mean()\n",
    "    std = r.std()\n",
    "    sharpe = (mean / std) * np.sqrt(252) if std != 0 else np.nan\n",
    "    return {\"VaR_95\": var95, \"mean_daily\": mean, \"std_daily\": std, \"sharpe\": sharpe}\n",
    "\n",
    "metrics = []\n",
    "for t in TICKERS:\n",
    "    m = var_sharpe(dfs[t])\n",
    "    m[\"ticker\"] = t\n",
    "    m[\"start\"] = dfs[t].index.min().date()\n",
    "    m[\"end\"] = dfs[t].index.max().date()\n",
    "    metrics.append(m)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).set_index(\"ticker\")\n",
    "display(metrics_df.round(6))\n",
    "metrics_df.to_csv(\"../data/processed/summary_metrics_task1.csv\")\n",
    "print(\"Saved summary to data/processed/summary_metrics_task1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56938f",
   "metadata": {},
   "source": [
    "## Key insights (example template)\n",
    "\n",
    "- TSLA shows a long-term upward trend but high volatility.\n",
    "- BND is stable with low volatility and smaller returns.\n",
    "- SPY tracks market movements and provides diversification.\n",
    "- ADF tests typically show non-stationary prices and stationary\n",
    "  log returns — we will difference prices for ARIMA if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412ff76",
   "metadata": {},
   "source": [
    "## Next steps (for Task 2)\n",
    "\n",
    "1. Decide whether to forecast prices, returns, or volatility.\n",
    "2. Prepare a chronological train/test split.\n",
    "3. Build and compare ARIMA (statsmodels) and LSTM (PyTorch)\n",
    "   models.\n",
    "4. Use forecasted returns for portfolio optimization in Task 4.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
